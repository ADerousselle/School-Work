{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2129a4a1-7432-4ab1-9c00-35c2a32a0339",
   "metadata": {},
   "source": [
    "Task 1: Write a function result = central_moment(image, i, j) that returns the (i, j) central moment of image, where image is a grayscale or binary image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f0aa7-5353-40af-82f7-b270ea037002",
   "metadata": {},
   "source": [
    "Task 2: Write a function result = normalized_moment(image, i, j) that returns the (i, j) normalized central moment of image, where image is a grayscale or binary image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3fccfd-51f9-47a3-8759-5a488e0d34eb",
   "metadata": {},
   "source": [
    "Task 3: Write a function result = hu_moment(image, m) that returns the m-th Hu moment of image, where image is a grayscale or binary image. Note that the lecture slides define 7 Hu moments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66731941-d1f2-48fa-a695-27174596c0c9",
   "metadata": {},
   "source": [
    "Task 4: Write a function prediction = knn_classify_digit_cm(digit, K, train_cmoments_db) that takes as input an image of a digit from the MNIST dataset and the number of neighbors (K) to use, and it predicts the label of the digit by performing a nearest neighbor search using central moments on the train_cmoments_db.\n",
    "The train_cmoments_db contains a database of precomputed central moments of 5000 digits. Each vector of central moments contains the following eight central moments <m00, m11, m20, m02, m21, m12, m30, m03> in that order. The database also contains the labels and the minimum and maximum value of any moment that was observed in the training set before they were normalized to the range [0, 1].\n",
    "You can extract the moment vectors, labels, min values and max values as:\n",
    "(train_cmoments, train_labels, min_vals, max_vals) = train_cmoments_db\n",
    "The algorithmic steps to implement the function are as follows:\n",
    "1. Compute a feature vector of the same central moments from the query digit.\n",
    "2. Normalize each moment to the range [0, 1], by using the min_vals and max_vals from the train_cmoments_db.\n",
    "3. Compute the Euclidean distance of the digit feature vector from each of the 5000 vectors in the database.\n",
    "4. Find the top K nearest neighbors.\n",
    "5. Assign the predicted label of the digit to be that of the majority of its top K neighbors. \n",
    " \n",
    "We will test your function by predicting the labels of digits 5001 to 6000 (1000 digits) from the MNIST database and comparing them to the true label. My solution predicts 747/1000 labels correctly for K=1 and 795/1000 for K=11. To get full credit, your solution should correctly predict at least 700/1000 digits. 5 out of the 40 points of this task will be allocated to code efficiency in terms of running time. To get full credit, your solution should take no more than three times as much as my solution for classifying the 1000 digits.\n",
    " \n",
    "Tips:\n",
    "The Euclidean distance between two feature vectors can be negatively affected if the range of values of one feature is much different than the range of values of another feature. To avoid such problems, we can scale all features to the range [0, 1]. In my solution, scaling improved the prediction accuracy by about 5%.\n",
    "Computing the Euclidean distance between the query digit feature vector and each of the 5000 feature vectors of our database in a loop is slow. Instead of a loop, use Numpy matrix operations to subtract the current moments vector from each row of the train_cmoments matrix and to compute all the distances in one operation.\n",
    "When computing the Euclidean distance, make sure to scale the query feature vector using the same min and max values that were calculated from the database feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b90da1-b43c-45a8-a6ba-4506bf983caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elapsed for prediction: 11.831400632858276 seconds\n",
      "\n",
      "Correctly predicted 795 out of 1000 digits\n",
      "Accuracy: 0.795\n",
      "\n",
      "Confusion matrix:\n",
      "[[103   0   1   2   0   0   0   0   2   0]\n",
      " [  1 110   0   0   0   1   2   0   1   0]\n",
      " [  4   0  84   2   0   1   2   0   2   0]\n",
      " [  2   0  13  67   0   5   1   1   5   1]\n",
      " [  4   0   0   0  73   2   4   0   0  16]\n",
      " [ 18   1   7  11   1  39   1   0  13   1]\n",
      " [  2   0   2   0   0   0  96   0   0   0]\n",
      " [  0   0   0   1   0   0   0  80   1  15]\n",
      " [ 12   2   3   1   4  15   2   2  57   0]\n",
      " [  0   0   0   0   0   0   0  13   2  86]]\n"
     ]
    }
   ],
   "source": [
    "#main operations\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from get_features_cm import get_features_cm\n",
    "from knn_classify_digit_cm import knn_classify_digit_cm\n",
    "\n",
    "data_file_path = \"data/mnist_data.csv\"\n",
    "################# Load the data #################\n",
    "# Load the data. Use ',' as the delimiter\n",
    "data = np.loadtxt(data_file_path, delimiter=',')\n",
    "labels = data[:, 0]\n",
    "data = data[:, 1:]\n",
    "# Reshape the data to be a list of 28x28 2D images\n",
    "data = data.reshape(data.shape[0], 28, 28)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data = data[:5000]\n",
    "train_labels = labels[:5000]\n",
    "\n",
    "test_data = data[5000:6000]\n",
    "test_labels = labels[5000:6000]\n",
    "########## Compute the central moments of training data ##########\n",
    "train_cmoments = np.zeros((train_data.shape[0], 8))\n",
    "for i in range(train_data.shape[0]):\n",
    "    train_cmoments[i] = get_features_cm(train_data[i])\n",
    "\n",
    "# Scale all features of the database to the range [0, 1]\n",
    "min_vals = np.min(train_cmoments, axis=0)\n",
    "max_vals = np.max(train_cmoments, axis=0)\n",
    "train_cmoments = (train_cmoments - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "train_cmoments_db = (train_cmoments, train_labels, min_vals, max_vals)\n",
    "\n",
    "\n",
    "################# Classify test data #################\n",
    "# Predict the labels of all test digits\n",
    "\n",
    "# Time the prediction process\n",
    "start_time = time.time()\n",
    "\n",
    "predictions = np.zeros(len(test_labels))\n",
    "K = 11\n",
    "for i in range(len(test_labels)):\n",
    "    # Predict the digit using the KNN classifier\n",
    "    digit = test_data[i,:,:]\n",
    "    predictions[i] = knn_classify_digit_cm(digit, K, train_cmoments_db)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('\\nTime elapsed for prediction: {} seconds'.format(elapsed_time))\n",
    "\n",
    "# Calculate the accuracy\n",
    "correct = np.sum(predictions == test_labels)\n",
    "total = len(test_labels)\n",
    "accuracy = correct / total\n",
    "\n",
    "print('\\nCorrectly predicted {} out of {} digits'.format(correct, total))\n",
    "print('Accuracy: {}'.format(accuracy))\n",
    "\n",
    "# Print confusion matrix\n",
    "print('\\nConfusion matrix:')\n",
    "print(confusion_matrix(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e21fb14-67f9-41e1-a4f9-a4b76251cdcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
