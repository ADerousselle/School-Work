{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedcf87b-1d82-4e01-ad77-45fcbc321b8d",
   "metadata": {},
   "source": [
    "Task 1 [50 points]: The goal of this task is to train and evaluate a convolutional neural network (CNN) model that can classify a given cropped input image as a face or not a face.\n",
    "\n",
    "Create a Python function named\n",
    "model = train_face_model(faces, nonfaces)\n",
    "\n",
    "that accepts a dataset of face images and a dataset of non-face images as matrices and returns a trained CNN model.\n",
    "The given face and non-face matrices are of shape (n_instances, height, width). Reshape the matrices as needed to pass them to your neural network for training. You also need to create appropriate labels for training.\n",
    "The function returns two objects, the training model and the training history.\n",
    "We will use a dataset of 1000 faces and 1000 non-faces to train and evaluate the model. The first 700 images of each class will be passed to your function for training, and the remaining 300 images of each class will be used for testing. Your model is expected to achieve a very high classification accuracy. My reference solution achieves >0.99 accuracy on the test set. To get full credit, your solution should achieve at least 0.97.\n",
    "Note: Before using the training data to train the model, you should scale their pixel values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c701b621-6e07-43c5-a753-03e11085a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def train_face_model(faces, nonfaces):\n",
    "    # Define labels for the datasets (1 for faces, 0 for non-faces)\n",
    "    num_faces = faces.shape[0]\n",
    "    num_nonfaces = nonfaces.shape[0]\n",
    "    labels = np.concatenate([np.ones(num_faces), np.zeros(num_nonfaces)])\n",
    "    \n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    faces = faces / 255.0\n",
    "    nonfaces = nonfaces / 255.0\n",
    "    \n",
    "    # Concatenate face and non-face images\n",
    "    all_images = np.concatenate([faces, nonfaces], axis=0)\n",
    "    \n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(faces.shape[1], faces.shape[2], 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Shuffle the data\n",
    "    all_images, labels = shuffle(all_images, labels, random_state=42)\n",
    "    \n",
    "    # Split the data into training and validation sets\n",
    "    split_point = 700  # Number of images for training\n",
    "    x_train = all_images[:split_point]\n",
    "    y_train = labels[:split_point]\n",
    "    x_val = all_images[split_point:]\n",
    "    y_val = labels[split_point:]\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d6729ff-7ce2-4270-8bd6-d392418c3258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faces dataset has the wrong number of dimensions. It should be a 3D NumPy array (height, width, channels).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFaces dataset shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfaces[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Check the number of channels in the first image of 'faces'\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m]:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFaces dataset has the wrong number of channels. It should be 1 (grayscale) or 3 (RGB).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from train_face_model import train_face_model  # Assuming you have saved the function in a separate file\n",
    "\n",
    "# Load your face and non-face datasets (make sure they are properly preprocessed and loaded as NumPy arrays)\n",
    "# Example:\n",
    "faces = np.load('data/faces1000.npy')\n",
    "nonfaces = np.load('data/nonfaces1000.npy')\n",
    "\n",
    "first_image = faces[0]\n",
    "print(f'First image shape: {first_image.shape}')\n",
    "print(f'First image values:\\n{first_image}')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "faces_train, faces_test = train_test_split(faces, test_size=300, random_state=42)\n",
    "nonfaces_train, nonfaces_test = train_test_split(nonfaces, test_size=300, random_state=42)\n",
    "\n",
    "# Call the training function\n",
    "model, history = train_face_model(faces_train, nonfaces_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_data = np.concatenate([faces_test, nonfaces_test], axis=0)\n",
    "test_labels = np.concatenate([np.ones(300), np.zeros(300)])\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "test_data = test_data / 255.0\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_data, test_labels)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53d2b3-f386-4122-9eea-07bf430f8a99",
   "metadata": {},
   "source": [
    "Task 2 [50 points]: Create a function\n",
    "result = cnn_face_search(image, scale, model, face_size, result_number)\n",
    "that can detect faces in photos at a given scale by using the face classification CNN model that we trained in task 1.\n",
    "\n",
    "The function returns a tuple containing two elements:\n",
    "A list of tuples, where each tuple contains the confidence score, center row and column coordinates of the detected face, and the top, bottom, left, and right coordinates of the bounding box around the face.\n",
    "A numpy array containing the confidence scores for each pixel in the input image.\n",
    "E.g.\n",
    "results, scores = cnn_face_search(img, model, face_size, scale, result_number)\n",
    "\n",
    "# Draw bounding boxes\n",
    "for result in results:\n",
    "    (max_val, best_row, best_col, top, bottom, left, right) = result\n",
    "    cv2.rectangle(img, (left, top), (right, bottom), 255, 2)\n",
    "Notes:\n",
    "The solution to this task is very similar to thechamfer_search that you implemented in assignment 6, except instead of computing a distance from a template to each window (patch) in the image, you are computing the probability that the window contains a face using the trained CNN model from task 1.\n",
    "As you iterate over all possible window positions in the input image, calling the model.predict() function thousands of times inside the loop is very slow. Instead, you should extract all windows and store them in a NumPy array of dimensions (n_windows, height, width). Then you can call model.predict(windows) once and get all the prediction probabilities. Each window is associated with a particular location in the original image, so you need to figure out a way to associate the top window candidates with the location they were extracted from in the image.\n",
    "The scale is measured with the respect to the original image face size. For example, if the original image face size is (31, 25) and the scale is 2.0, then the scaled face size will be (62, 50). Since you cannot scale the size of the trained model, you can scale the input image to 1.0/scale.\n",
    "Ensure the input image pixel values are scaled to [0,1] before attempting to apply the prediction model.\n",
    "My solution almost always detects the faces in faces.bmp at scale 2 correctly, as the top two results. However, for the faces in vjm.bmp, at scale 1, sometimes it detects all three of them as the top three results and sometimes it doesn't. That depends on how the model that I trained converged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
